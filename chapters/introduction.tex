\chapter*{Introduction}
\addcontentsline{toc}{chapter}{Introduction}

The phenomenon of learning has been a topic of interest for many generations of researchers. Though there is no consensus on the exact types of experiences that produce long lasting, behavior altering effects, games seem to play a key role in learning, especially in early developmental stages of the brain. In fact, it seems that most animals learn by playing games, at least initially -- from kittens and puppies acquiring necessary skills for survival by play-fighting; to humans learning ways to solve a variety of abstract and complex tasks through the multitude of games they play in their childhood. 
\\\\
Given the role games have in the formation of animal’s intelligence, it is no wonder that developing and evaluating Artificial Intelligence (AI) agents has been historically done through games - from the very first attempts at AI in checkers~\cite{Samuel1959} to modern explosion of Reinforcement Learning (RL) based AIs in classical board games such as Go~\cite{Silver2016}, and in video games such as Atari platform~\cite{Mnih2015}, Ms. Pac-Man~\cite{Seijen2017}, and Doom~\cite{Kempka2016}. 
\\\\
Company DeepMind in particular has been actively pushing the boundaries of machine learning based AIs. After IBM’s Deep Blue victory over Kasparov in chess, Go was widely seen as the next great challenge for AI. Having significantly bigger state space and branching factor than chess, it was assumed by many AI researchers that it might take another decade before competitive Go AI emerged. Which is why DeepMind’s decisive victory over Go world champion Lee Sedol in March 2016 was as significant as Deep Blue and has solidified DeepMind’s reputation as one of the world's leading AI research laboratories.
\\\\
A short time after their achievement in Go, DeepMind has announced StarCraft II -- a popular real-time strategy video game -- as their next research target. In cooperation with Blizzard Entertainment, DeepMind has released StarCraft II Learning Environment (SC2LE): a set of easy to use tools and libraries to connect with the StarCraft II game and enable training of RL based AI. 
\\\\
Alongside SC2LE, DeepMind has released a paper describing their baseline end-to-end RL agent architecture. This agent learns from input data similar to what a human player would perceive and makes choices from the same action options a human player would have~\cite{Vinyals2017}. Described agent was evaluated on a set of mini-games and their results were recorded as a benchmark for future research attempts. For comparison’s sake, DeepMind has also recorded results from two humans: an amateur player, and professional expert.
\\\\
However, one key piece is missing from DeepMind's contribution to the field of RL-based AI -- namely, the source code of their benchmark agent was not made public along with the scientific publication. Without the source code, the publication provides only general guidelines, but not the exact details on how to recreate the AI agent described in the paper.
\\\\
Focus of this thesis is to explore modern Reinforcement Learning based approaches by replicating and open-sourcing DeepMind’s baseline architecture, following described specification as closely as possible and ensuring that implemented agent is capable of achieving set benchmark results.